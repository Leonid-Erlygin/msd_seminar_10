{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained CPC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubconf import CPC_audio\n",
    "cpc = CPC_audio(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpc.eval.linear_separability import run, parse_args\n",
    "from cpc.dataset import AudioBatchData, findAllSeqs, filterSeqs, parseSeqLabels\n",
    "import cpc.criterion as cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = [\n",
    " '/app/data/LibriSpeech',\n",
    " '/app/data/LibriSpeech/train_split_small.txt',\n",
    " '/app/data/LibriSpeech/test_split_small.txt',\n",
    " '/app/data/checkpoints/60k_epoch4-d0f474de.pt',\n",
    " '--pathCheckpoint',\n",
    " '/app/data/checkpoints/',\n",
    " '--pathPhone',\n",
    " '/app/data/converted_aligned_phones.txt']\n",
    "\n",
    "args = parse_args(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache /app/data/LibriSpeech/_seqs_cache.txt successfully\n",
      "Running phone separability with aligned phones\n"
     ]
    }
   ],
   "source": [
    "logs = {\"epoch\": [], \"iter\": [], \"saveStep\": -1}\n",
    "load_criterion = False\n",
    "\n",
    "seqNames, speakers = findAllSeqs(args.pathDB,\n",
    "                                    extension=args.file_extension,\n",
    "                                    loadCache=not args.ignore_cache)\n",
    "\n",
    "model, hidden_gar, hidden_encoder = cpc, cpc.gAR.getDimOutput(), cpc.gEncoder.getDimOutput()\n",
    "\n",
    "model.cuda()\n",
    "model = torch.nn.DataParallel(model, device_ids=range(args.nGPU))\n",
    "\n",
    "dim_features = hidden_encoder if args.get_encoded else hidden_gar\n",
    "\n",
    "# Now the criterion\n",
    "phone_labels = None\n",
    "\n",
    "phone_labels, n_phones = parseSeqLabels(args.pathPhone)\n",
    "\n",
    "print(f\"Running phone separability with aligned phones\")\n",
    "criterion = cr.PhoneCriterion(dim_features,\n",
    "                                n_phones, args.get_encoded)\n",
    "\n",
    "criterion.cuda()\n",
    "criterion = torch.nn.DataParallel(criterion, device_ids=range(args.nGPU))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20480"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.size_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking length...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:00, 177451.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, elapsed: 0.112 seconds\n",
      "Scanned 44 sequences in 0.11 seconds\n",
      "1 chunks computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool\n",
      "Joined process, elapsed=0.954 secs\n",
      "Checking length...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:00, 292845.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, elapsed: 0.112 seconds\n",
      "Scanned 62 sequences in 0.11 seconds\n",
      "1 chunks computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "seq_train = filterSeqs(args.pathTrain, seqNames)\n",
    "seq_val = filterSeqs(args.pathVal, seqNames)\n",
    "\n",
    "\n",
    "db_train = AudioBatchData(args.pathDB, args.size_window, seq_train,\n",
    "                            phone_labels, len(speakers))\n",
    "db_val = AudioBatchData(args.pathDB, args.size_window, seq_val,\n",
    "                        phone_labels, len(speakers))\n",
    "\n",
    "batch_size = args.batchSizeGPU * args.nGPU\n",
    "\n",
    "train_loader = db_train.getDataLoader(batch_size, \"uniform\", True,\n",
    "                                        numWorkers=0)\n",
    "\n",
    "val_loader = db_val.getDataLoader(batch_size, 'sequential', False,\n",
    "                                    numWorkers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_params = list(criterion.parameters())\n",
    "model.optimize = False\n",
    "model.eval()\n",
    "if args.unfrozen:\n",
    "    print(\"Working in full fine-tune mode\")\n",
    "    g_params += list(model.parameters())\n",
    "    model.optimize = True\n",
    "else:\n",
    "    print(\"Working with frozen features\")\n",
    "    for g in model.parameters():\n",
    "        g.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(g_params, lr=args.lr,\n",
    "                                betas=(args.beta1, args.beta2),\n",
    "                                eps=args.epsilon)\n",
    "\n",
    "# Checkpoint directory\n",
    "args.pathCheckpoint = Path(args.pathCheckpoint)\n",
    "args.pathCheckpoint.mkdir(exist_ok=True)\n",
    "args.pathCheckpoint = str(args.pathCheckpoint / \"checkpoint\")\n",
    "\n",
    "with open(f\"{args.pathCheckpoint}_args.json\", 'w') as file:\n",
    "    json.dump(vars(args), file, indent=2)\n",
    "\n",
    "run(model, criterion, train_loader, val_loader, optimizer, logs,\n",
    "    args.n_epoch, args.pathCheckpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d9146f3a31216435d9751eb96fbc7d8f8917747d9834770cb31ae30f640a05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
