{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained CPC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubconf import CPC_audio\n",
    "cpc = CPC_audio(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpc.eval.linear_separability import run, parse_args\n",
    "from cpc.dataset import AudioBatchData, findAllSeqs, filterSeqs, parseSeqLabels\n",
    "import cpc.criterion as cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = [\n",
    " '/app/data/LibriSpeech',\n",
    " '/app/data/LibriSpeech/train_split_small.txt',\n",
    " '/app/data/LibriSpeech/test_split_small.txt',\n",
    " '/app/data/checkpoints/60k_epoch4-d0f474de.pt',\n",
    " '--pathCheckpoint',\n",
    " '/app/data/checkpoints/',\n",
    " '--pathPhone',\n",
    " '/app/data/converted_aligned_phones.txt']\n",
    "\n",
    "args = parse_args(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache /app/data/LibriSpeech/_seqs_cache.txt successfully\n",
      "Running phone separability with aligned phones\n"
     ]
    }
   ],
   "source": [
    "logs = {\"epoch\": [], \"iter\": [], \"saveStep\": -1}\n",
    "load_criterion = False\n",
    "\n",
    "seqNames, speakers = findAllSeqs(args.pathDB,\n",
    "                                    extension=args.file_extension,\n",
    "                                    loadCache=not args.ignore_cache)\n",
    "\n",
    "model, hidden_gar, hidden_encoder = cpc, cpc.gAR.getDimOutput(), cpc.gEncoder.getDimOutput()\n",
    "\n",
    "model.cuda()\n",
    "model = torch.nn.DataParallel(model, device_ids=range(args.nGPU))\n",
    "\n",
    "dim_features = hidden_encoder if args.get_encoded else hidden_gar\n",
    "\n",
    "# Now the criterion\n",
    "phone_labels = None\n",
    "\n",
    "phone_labels, n_phones = parseSeqLabels(args.pathPhone)\n",
    "\n",
    "print(f\"Running phone separability with aligned phones\")\n",
    "criterion = cr.PhoneCriterion(dim_features,\n",
    "                                n_phones, args.get_encoded)\n",
    "\n",
    "criterion.cuda()\n",
    "criterion = torch.nn.DataParallel(criterion, device_ids=range(args.nGPU))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking length...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:00, 177451.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, elapsed: 0.112 seconds\n",
      "Scanned 44 sequences in 0.11 seconds\n",
      "1 chunks computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool\n",
      "Joined process, elapsed=0.954 secs\n",
      "Checking length...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:00, 292845.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, elapsed: 0.112 seconds\n",
      "Scanned 62 sequences in 0.11 seconds\n",
      "1 chunks computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m seq_val \u001b[39m=\u001b[39m filterSeqs(args\u001b[39m.\u001b[39mpathVal, seqNames)\n\u001b[1;32m      6\u001b[0m db_train \u001b[39m=\u001b[39m AudioBatchData(args\u001b[39m.\u001b[39mpathDB, args\u001b[39m.\u001b[39msize_window, seq_train,\n\u001b[1;32m      7\u001b[0m                             phone_labels, \u001b[39mlen\u001b[39m(speakers))\n\u001b[0;32m----> 8\u001b[0m db_val \u001b[39m=\u001b[39m AudioBatchData(args\u001b[39m.\u001b[39;49mpathDB, args\u001b[39m.\u001b[39;49msize_window, seq_val,\n\u001b[1;32m      9\u001b[0m                         phone_labels, \u001b[39mlen\u001b[39;49m(speakers))\n\u001b[1;32m     11\u001b[0m batch_size \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mbatchSizeGPU \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mnGPU\n\u001b[1;32m     13\u001b[0m train_loader \u001b[39m=\u001b[39m db_train\u001b[39m.\u001b[39mgetDataLoader(batch_size, \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m                                         numWorkers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/app/cpc/dataset.py:65\u001b[0m, in \u001b[0;36mAudioBatchData.__init__\u001b[0;34m(self, path, sizeWindow, seqNames, phoneLabelsDict, nSpeakers, nProcessLoader, MAX_SIZE_LOADED)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphoneLabelsDict \u001b[39m=\u001b[39m deepcopy(phoneLabelsDict)\n\u001b[1;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadNextPack(first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloadNextPack()\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdoubleLabels \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/app/cpc/dataset.py:127\u001b[0m, in \u001b[0;36mAudioBatchData.loadNextPack\u001b[0;34m(self, first)\u001b[0m\n\u001b[1;32m    125\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    126\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mJoining pool\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    128\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mJoined process, elapsed=\u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m secs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnextData \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "seq_train = filterSeqs(args.pathTrain, seqNames)\n",
    "seq_val = filterSeqs(args.pathVal, seqNames)\n",
    "\n",
    "\n",
    "db_train = AudioBatchData(args.pathDB, args.size_window, seq_train,\n",
    "                            phone_labels, len(speakers))\n",
    "db_val = AudioBatchData(args.pathDB, args.size_window, seq_val,\n",
    "                        phone_labels, len(speakers))\n",
    "\n",
    "batch_size = args.batchSizeGPU * args.nGPU\n",
    "\n",
    "train_loader = db_train.getDataLoader(batch_size, \"uniform\", True,\n",
    "                                        numWorkers=0)\n",
    "\n",
    "val_loader = db_val.getDataLoader(batch_size, 'sequential', False,\n",
    "                                    numWorkers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_params = list(criterion.parameters())\n",
    "model.optimize = False\n",
    "model.eval()\n",
    "if args.unfrozen:\n",
    "    print(\"Working in full fine-tune mode\")\n",
    "    g_params += list(model.parameters())\n",
    "    model.optimize = True\n",
    "else:\n",
    "    print(\"Working with frozen features\")\n",
    "    for g in model.parameters():\n",
    "        g.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(g_params, lr=args.lr,\n",
    "                                betas=(args.beta1, args.beta2),\n",
    "                                eps=args.epsilon)\n",
    "\n",
    "# Checkpoint directory\n",
    "args.pathCheckpoint = Path(args.pathCheckpoint)\n",
    "args.pathCheckpoint.mkdir(exist_ok=True)\n",
    "args.pathCheckpoint = str(args.pathCheckpoint / \"checkpoint\")\n",
    "\n",
    "with open(f\"{args.pathCheckpoint}_args.json\", 'w') as file:\n",
    "    json.dump(vars(args), file, indent=2)\n",
    "\n",
    "run(model, criterion, train_loader, val_loader, optimizer, logs,\n",
    "    args.n_epoch, args.pathCheckpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d9146f3a31216435d9751eb96fbc7d8f8917747d9834770cb31ae30f640a05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
